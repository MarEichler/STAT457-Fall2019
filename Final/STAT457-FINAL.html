
<!DOCTYPE html>
<html>
<head>
<style type="text/css">
.inline {
  background-color: #f7f7f7;
  border:solid 1px #B0B0B0;
}
.error {
	font-weight: bold;
	color: #FF0000;
}
.warning {
	font-weight: bold;
}
.message {
	font-style: italic;
}
.source, .output, .warning, .error, .message {
	padding: 0 1em;
  border:solid 1px #F7F7F7;
}
.source {
  background-color: #f5f5f5;
}
.left {
  text-align: left;
}
.right {
  text-align: right;
}
.center {
  text-align: center;
}
.hl.num {
  color: #AF0F91;
}
.hl.str {
  color: #317ECC;
}
.hl.com {
  color: #AD95AF;
  font-style: italic;
}
.hl.opt {
  color: #000000;
}
.hl.std {
  color: #585858;
}
.hl.kwa {
  color: #295F94;
  font-weight: bold;
}
.hl.kwb {
  color: #B05A65;
}
.hl.kwc {
  color: #55aa55;
}
.hl.kwd {
  color: #BC5A65;
  font-weight: bold;
}
</style>
  <script src="https://yihui.name/media/js/center-images.js"></script>
  <title>A Report Generated by knitr</title>
</head>
<body>

  <p>This report is automatically generated with the R
    package <a href="https://yihui.name/knitr/"><strong>knitr</strong></a>
    (version <code class="knitr inline">1.24</code>)
    .</p>

<div class="chunk" id="auto-report"><div class="rcode"><div class="source"><pre class="knitr r">---
title: <span class="hl str">&quot;STAT 457 - FINAL&quot;</span>
author: <span class="hl str">&quot;Martha Eichlersmith&quot;</span>
date: <span class="hl str">&quot;2019-12-12&quot;</span>
output: 
  pdf_document:
    fig_caption: yes
<span class="hl com">#    number_sections: true</span>
header-includes: 
- \usepackage{color}
- \usepackage{mathtools}
- \usepackage{bbm} <span class="hl com">#<span class="hl kwa">for</span> mathbb <span class="hl kwa">for</span> numbers</span>
- \usepackage{amsbsy}
- \usepackage{caption} <span class="hl com">#to remove automatic table name and number - \captionsetup[table]{labelformat=empty}, put code under YAML</span>
- \usepackage{booktabs}
- \usepackage{geometry}
- \usepackage{float} <span class="hl com">#to hold things <span class="hl kwa">in</span> place</span>
- \floatplacement{figure}{H}
- \usepackage{lastpage}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhf{}
- \fancyhead[L]{STAT 457 Fall 2019 \\ Final}
- \fancyhead[R]{Martha Eichlersmith \\ Page \thepage\ of\ \pageref*{LastPage}}  
- \setlength{\headheight}{22.5pt} <span class="hl com">#to remove \fancyhead error <span class="hl kwa">for</span> head height</span>
geometry: <span class="hl str">&quot;left=0.75in,right=0.75in,top=1.1in,bottom=1in&quot;</span> 
---

\captionsetup[table]{labelformat=empty}
```{r setup, echo=<span class="hl kwa">FALSE</span>, results=<span class="hl str">&quot;hide&quot;</span>, warning=<span class="hl kwa">FALSE</span>, message=<span class="hl kwa">FALSE</span>}
<span class="hl kwd">library</span>(ggplot2) #ggplot
<span class="hl kwd">library</span>(gridExtra) #organize plots
<span class="hl kwd">library</span>(grid) #organize plots
<span class="hl kwd">library</span>(latex2exp) #latex <span class="hl kwa">in</span> ggplot titles 
<span class="hl kwd">library</span>(dplyr) #<span class="hl kwa">for</span> piping 
<span class="hl kwd">library</span>(MASS)
<span class="hl kwd">library</span>(invgamma)
knitr::opts_chunk$<span class="hl kwd">set</span>(fig.width = 10, fig.height = 4)
knitr::opts_chunk$<span class="hl kwd">set</span>(echo=<span class="hl kwa">FALSE</span>)
decimal &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(x, k) <span class="hl kwd">trimws</span>(<span class="hl kwd">format</span>(<span class="hl kwd">round</span>(x, k), nsmall=k))
dec &lt;- 5
```

\newpage  
<span class="hl com"># Problem 1  </span>
<span class="hl com">## Problem 1a  </span>
For the data $Y = (125,18,20,34)$, implement the Gibbs sampler algorithm.  Use a flat prior on $\theta$.  
Plot $\theta^i$ versus iteration $i$. 
$Y = (y_1, y_2, y_3, y_4) <span class="hl kwd">\propto</span> (2 + \theta, 1 - \theta, 1 - \theta, \theta)$  
1. Draw a starting value, $t \sim$<span class="hl kwd">Uniform</span>(0,1)  
2. Draw a latent value, $Z \sim \text{Binomial}<span class="hl kwd">\left</span>( y_1, \ \frac{ \theta}{2 + \theta} \right)$  
3. Draw a parameter, $\theta \sim \text{Beta}( Z+y_4 + 1, y_2 + y_3 + 1)$  

```{r p1.func_chain}
func_chain &lt;-<span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, Y){
  <span class="hl kwd">set.seed</span>(startseed)
  t &lt;- <span class="hl kwd">runif</span>(1)
  theta &lt;- t
  chain&lt;- <span class="hl kwd">c</span>()#<span class="hl kwd">rep</span>(<span class="hl kwa">NA</span>, 10000)
  chain[1]&lt;-theta
  Z.i&lt;-<span class="hl kwd">rbinom</span>(1,Y[1],(theta/(theta+2)))
  theta.i&lt;-<span class="hl kwd">rbeta</span>(1,Z.i+Y[4]+1,Y[2]+Y[3]+1)
  chain[2]&lt;-theta.i
  Z.i&lt;-<span class="hl kwd">rbinom</span>(1,Y[1],(theta.i/(theta.i+2)))
  theta.i&lt;-<span class="hl kwd">rbeta</span>(1,Z.i+Y[1]+1,Y[2]+Y[3]+1)
  chain[3]&lt;-theta.i
  k&lt;-3
    <span class="hl kwd"><span class="hl kwa">while</span></span>(<span class="hl kwd">abs</span>(chain[k]-chain[k-1]) &gt;= 0.000001) {
      Z.i&lt;-<span class="hl kwd">rbinom</span>(1,Y[1], (theta.i/(theta.i+2)))
      theta.i&lt;-<span class="hl kwd">rbeta</span>(1,Z.i+Y[4]+1,Y[2]+Y[3]+1)
      k&lt;-k+1
      chain[k]&lt;-theta.i
    }
  chain&lt;-chain[!<span class="hl kwd">is.na</span>(chain)]
  chain
}
```

```{r p1.scale_funcs}
func_scalelike&lt;-<span class="hl kwd"><span class="hl kwa">function</span></span>(x,y1,y2,y3,y4){
  like &lt;-(2+x)^y1*(1-x)^(y2+y3)*(x)^y4
  like.max&lt;-<span class="hl kwd">max</span>(like)
  like/like.max #normalized <span class="hl kwd">likelihood</span> (on scale from 0 to 1) 
}

func_scalenormal&lt;-<span class="hl kwd"><span class="hl kwa">function</span></span>(x, mean, sd){
  scales::<span class="hl kwd">rescale</span>(<span class="hl kwd">dnorm</span>(x, mean, sd), to=<span class="hl kwd">c</span>(0, 1)) #<span class="hl kwd">normal</span> (on scale from 0 to 1) 
}
```

```{r p1.func_p1AB}
func_problem1AB &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, Y, number){

chain &lt;- <span class="hl kwd">func_chain</span>(startseed, Y)
  
df.chain &lt;- <span class="hl kwd">data.frame</span>(
        <span class="hl str">&quot;theta.i&quot;</span> = chain,
        <span class="hl str">&quot;i&quot;</span>=<span class="hl kwd">c</span>(1:<span class="hl kwd">length</span>(chain))
)

chain.mu &lt;- <span class="hl kwd">mean</span>(chain)
chain.sd &lt;- <span class="hl kwd">sd</span>(chain)
table &lt;- <span class="hl kwd">data.frame</span>(
  <span class="hl str">&quot;Name&quot;</span> = <span class="hl kwd">c</span>(<span class="hl str">&quot;Mean&quot;</span>, <span class="hl str">&quot;SD&quot;</span>, <span class="hl str">&quot;it&quot;</span>, <span class="hl str">&quot;Start&quot;</span>),
  <span class="hl str">&quot;Value&quot;</span> = <span class="hl kwd">c</span>(
    <span class="hl kwd">decimal</span>(chain.mu, dec), 
    <span class="hl kwd">decimal</span>(chain.sd, dec), 
    <span class="hl kwd">decimal</span>(<span class="hl kwd">length</span>(chain), 0),
    <span class="hl kwd">decimal</span>(chain[1], dec)
  )
)
tg &lt;- <span class="hl kwd">tableGrob</span>(table)

print.Y &lt;- <span class="hl kwd">paste</span>(Y, collapse = <span class="hl str">&quot;,&quot;</span>)

#plot theta_i versus <span class="hl kwd">i</span> (iterations)
plot.Gibbs &lt;- <span class="hl kwd">ggplot</span>(df.chain, <span class="hl kwd">aes</span>(x=i, y=theta.i))+
  <span class="hl kwd">geom_line</span>(alpha=0.4)+
  <span class="hl kwd">ggtitle</span>(<span class="hl str">&quot;Gibbs Sampler&quot;</span>)


colors &lt;- <span class="hl kwd">c</span>(<span class="hl str">&quot;navy&quot;</span>, <span class="hl str">&quot;maroon&quot;</span>)
norm.like &lt;-<span class="hl kwd">stat_function</span>(
  fun = func_scalelike
  , args = <span class="hl kwd">list</span>(y1=Y[1], y2=Y[2], y3=Y[3], y4=Y[4])
  , lwd = 1
  , linetype=<span class="hl str">&quot;solid&quot;</span>
  , <span class="hl kwd">aes</span>(col=<span class="hl str">&quot;Normalized Like.&quot;</span>)
  )
normal.approx &lt;-<span class="hl kwd">stat_function</span>(
  fun = func_scalenormal
  , args = <span class="hl kwd">list</span>(mean=chain.mu, sd=chain.sd)
  , lwd = 1.5
  , linetype=<span class="hl str">&quot;dotted&quot;</span>
  , <span class="hl kwd">aes</span>(col=<span class="hl str">&quot;Normal Approx.&quot;</span>))

name &lt;- <span class="hl kwd">paste</span>(<span class="hl str">&quot;Normal Likelihood and Normal Approx&quot;</span>)

<span class="hl com">#print normalized likelihoods </span>
x &lt;- <span class="hl kwd">seq</span>(0, 1, 0.001)
df.x &lt;- <span class="hl kwd">data.frame</span>(<span class="hl str">&quot;X&quot;</span>=x)
plot.Like &lt;-  <span class="hl kwd">ggplot</span>(data=df.x, <span class="hl kwd">aes</span>(x=X))+
  norm.like+normal.approx+
  <span class="hl kwd">ggtitle</span>(<span class="hl kwd">paste</span>(name))+
  <span class="hl kwd">theme</span>(  axis.title.x = <span class="hl kwd">element_blank</span>()
         ,axis.title.y = <span class="hl kwd">element_blank</span>()
         ,axis.text.x = <span class="hl kwd">element_blank</span>()
         ,axis.text.y = <span class="hl kwd">element_blank</span>()
        )+
  <span class="hl kwd">scale_colour_manual</span>(<span class="hl str">&quot;&quot;</span>, values = <span class="hl kwd">c</span>(colors[1], colors[2])) +
  <span class="hl kwd">theme</span>(legend.position = <span class="hl kwd">c</span>(.2,.9))

main &lt;- <span class="hl kwd">paste</span>(<span class="hl str">&quot;Chain&quot;</span>, number, <span class="hl str">&quot;<span class="hl kwa">for</span> data <span class="hl kwa">for</span> Y=(&quot;</span>, print.Y, <span class="hl str">&quot;)&quot;</span>)

gs &lt;- <span class="hl kwd">list</span>(plot.Gibbs, tg, plot.Like)
<span class="hl kwd">grid.arrange</span>(grobs=gs, nrow=1, widths=<span class="hl kwd">c</span>(2, 1, 2),
             top = <span class="hl kwd">textGrob</span>(main, vjust = .5, gp = <span class="hl kwd">gpar</span>(fontface = <span class="hl str">&quot;bold&quot;</span>, cex = 1.2))
            )
}
```

```{r p1aRESULT, fig.height=2}
Y.A &lt;- <span class="hl kwd">c</span>(125, 18, 20, 34)

<span class="hl kwd">func_problem1AB</span>(111, Y.A, 1)
<span class="hl kwd">func_problem1AB</span>(112, Y.A, 2)
<span class="hl kwd">func_problem1AB</span>(113, Y.A, 3)
<span class="hl kwd">func_problem1AB</span>(114, Y.A, 4)
<span class="hl kwd">func_problem1AB</span>(115, Y.A, 5)
```

\newpage 
<span class="hl com">## Problem 1b  </span>
Repeat 1a <span class="hl kwa">for</span> $Y = (14, 0, 1, 5)$.  
```{r p1bRESULT, fig.height=2}
Y.B &lt;- <span class="hl kwd">c</span>(14,0,1,5)

<span class="hl kwd">func_problem1AB</span>(121, Y.B, 1)
<span class="hl kwd">func_problem1AB</span>(122, Y.B, 2)
<span class="hl kwd">func_problem1AB</span>(123, Y.B, 3)
<span class="hl kwd">func_problem1AB</span>(124, Y.B, 4)
<span class="hl kwd">func_problem1AB</span>(125, Y.B, 5)
```
There is a lack of fit <span class="hl kwa">for</span> the data <span class="hl kwa">in</span> 1b, where the fit appears to be better <span class="hl kwa">for</span> data <span class="hl kwa">in</span> 1a. Convergence was assessed when values were had a difference less than $10^{-7}$.   


\newpage
<span class="hl com">## Problem 1c   </span>
```{r p1.func_chaininfo}
func_chaininfo &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, Y){
chain &lt;- <span class="hl kwd">func_chain</span>(startseed, Y)
it &lt;- <span class="hl kwd">length</span>(chain)
chain.mu &lt;- <span class="hl kwd">mean</span>(chain)
chain.sd &lt;- <span class="hl kwd">sd</span>(chain)
chain.se &lt;- chain.sd/<span class="hl kwd">sqrt</span>(it)
vec &lt;-<span class="hl kwd">c</span>(chain.mu, chain.sd, chain.se, it)
<span class="hl kwd">return</span>(vec)
}
```

```{r p1cRESULT20chains}
Y.C &lt;- <span class="hl kwd">c</span>(125, 18, 20, 34)
print.Y.C &lt;- <span class="hl kwd">paste</span>(Y.C, collapse=<span class="hl str">&quot;,&quot;</span>)
cnames &lt;- <span class="hl kwd">c</span>(<span class="hl str">&quot;Mean&quot;</span>, <span class="hl str">&quot;Standard Deviation&quot;</span>, <span class="hl str">&quot;Standard Error&quot;</span>, <span class="hl str">&quot;Iterations&quot;</span>)
info.20chain &lt;- <span class="hl kwd">mapply</span>(func_chaininfo, startseed=<span class="hl kwd">c</span>(1:20), Y=<span class="hl kwd">rep</span>(<span class="hl kwd">list</span>(Y.C), 20))
info.20chain &lt;- <span class="hl kwd">t</span>(info.20chain)
<span class="hl kwd">colnames</span>(info.20chain) &lt;- cnames

knitr::<span class="hl kwd">kable</span>(info.20chain, align=<span class="hl str">'rrrr'</span>, digits=dec, caption=<span class="hl kwd">paste</span>(<span class="hl str">&quot;20 Chains <span class="hl kwa">for</span> Y=(&quot;</span>, print.Y.C, <span class="hl str">&quot;)&quot;</span>))
```

```{r p1cRESULTavgsd.vs.se}
sd.of.avgs &lt;- <span class="hl kwd">sd</span>(info.20chain[,1])
avg.of.se &lt;- <span class="hl kwd">mean</span>(info.20chain[,3])

<span class="hl kwd">paste</span>(<span class="hl kwd">round</span>(sd.of.avgs, dec+1), <span class="hl str">&quot;is the standard deviation of the 20 averages of theta&quot;</span>)
<span class="hl kwd">paste</span>(<span class="hl kwd">decimal</span>(avg.of.se, dec+1), <span class="hl str">&quot;is the average of the standard errors of the 20 chains of theta&quot;</span>)
```

You would expected these values to be similar but it appears that our standard error average is under-estimating the variation <span class="hl kwa">in</span> the chain means of $\theta$ <span class="hl kwa">in</span> this case.  

\newpage  
<span class="hl com"># Problem 2  </span>

<span class="hl com">## Problem 2a  </span>
For the genetic linkage model applied to $Y = (125, 18, 20, 34)$, implement the Metropolis algorithm.  
(use a flat prior on $\theta)$.  Use one long chain and plot $\theta^i$ versus $i$.  
Try several driver functions: 

```{r p2.func_pi,func_Metropolis,func_drivers}
func_pi &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(theta, Y){
  (2+theta)^(Y[1]) * (1 - theta)^(Y[2]+Y[3]) * (theta)^(Y[4])
}

m &lt;- 10

#theta.i = <span class="hl kwd">X</span> (old value)
#theta.j = <span class="hl kwd">Y</span> (new value) 
theta.i &lt;- 0.1
Y &lt;- <span class="hl kwd">c</span>(125, 18, 20, 34)

func_MetroFix &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, m, Y, driver){
  <span class="hl com">#fixed driver </span>
  <span class="hl kwd">set.seed</span>(startseed)
  theta.i &lt;- <span class="hl kwd">runif</span>(1)
  chain &lt;- <span class="hl kwd">c</span>()
  alpha &lt;- <span class="hl kwd">c</span>()
  chain[1] &lt;- theta.i
  <span class="hl kwd"><span class="hl kwa">for</span></span> (k <span class="hl kwa">in</span> 2:m){
    theta.j &lt;- <span class="hl kwd">driver</span>(1)
    alpha.ij &lt;- <span class="hl kwd">min</span>(<span class="hl kwd">c</span>(1, <span class="hl kwd">func_pi</span>(theta.j, Y)/<span class="hl kwd">func_pi</span>(theta.i, Y)))
    <span class="hl kwd"><span class="hl kwa">if</span></span> (theta.j &gt;1 | theta.j &lt;0){alpha.ij &lt;- 0}
    u &lt;- <span class="hl kwd">runif</span>(1)
    <span class="hl kwd"><span class="hl kwa">if</span></span>( u &lt; alpha.ij){theta.i &lt;- theta.j}
    chain[k] &lt;- theta.i
  }
  chain
}

func_MetroDyn &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, m, Y, driver){
  <span class="hl com">#dynamic driver </span>
  <span class="hl kwd">set.seed</span>(startseed)
  theta.i &lt;- <span class="hl kwd">runif</span>(1)
  chain &lt;- <span class="hl kwd">c</span>()
  alpha &lt;- <span class="hl kwd">c</span>()
  chain[1] &lt;- theta.i
  <span class="hl kwd"><span class="hl kwa">for</span></span> (k <span class="hl kwa">in</span> 2:m){
    theta.j &lt;- <span class="hl kwd">driver</span>(1, theta.i)
    alpha.ij &lt;- <span class="hl kwd">min</span>(<span class="hl kwd">c</span>(1, <span class="hl kwd">func_pi</span>(theta.j, Y)/<span class="hl kwd">func_pi</span>(theta.i, Y)))
    <span class="hl kwd"><span class="hl kwa">if</span></span> (theta.j &gt;1 | theta.j &lt;0){alpha.ij &lt;- 0}
    u &lt;- <span class="hl kwd">runif</span>(1)
    <span class="hl kwd"><span class="hl kwa">if</span></span>( u &lt; alpha.ij){theta.i &lt;- theta.j}
    chain[k] &lt;- theta.i
  }
  chain
}

func_driver1.Uniform &lt;-    <span class="hl kwd"><span class="hl kwa">function</span></span>(n){<span class="hl kwd">runif</span>(n, min=0, max=1) }
func_driver2.Norm.sd.01 &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(n, mu){<span class="hl kwd">rnorm</span>(n, mean=mu, sd=0.01)}
func_driver3.Norm.sd.1 &lt;-  <span class="hl kwd"><span class="hl kwa">function</span></span>(n, mu){<span class="hl kwd">rnorm</span>(n, mean=mu, sd=0.1)}
func_driver4.Norm.sd.5 &lt;-  <span class="hl kwd"><span class="hl kwa">function</span></span>(n, mu){<span class="hl kwd">rnorm</span>(n, mean=mu, sd=0.5)}
func_driver5.Norm.mu.4sd.5 &lt;-  <span class="hl kwd"><span class="hl kwa">function</span></span>(n){<span class="hl kwd">rnorm</span>(n, mean=0.4, sd=0.5)}
```


```{r p2.func_p2ABC}
func_problem2ABC &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(chain, driver.name){
<span class="hl com">#main title</span>
print.Y &lt;- <span class="hl kwd">paste</span>(Y, collapse=<span class="hl str">&quot;,&quot;</span>)
main &lt;- <span class="hl kwd">paste</span>(<span class="hl str">&quot;Metropolis <span class="hl kwa">for</span> data Y=(&quot;</span>, print.Y, <span class="hl str">&quot;) using the driver&quot;</span>, driver.name)

df &lt;- <span class="hl kwd">data.frame</span>(
         <span class="hl str">&quot;theta.i&quot;</span>=chain
        ,<span class="hl str">&quot;i&quot;</span>=<span class="hl kwd">c</span>(1:<span class="hl kwd">length</span>(chain))
)


<span class="hl com">#table grob</span>
chain.mu &lt;- <span class="hl kwd">mean</span>(chain)
chain.sd &lt;- <span class="hl kwd">sd</span>(chain)
table &lt;- <span class="hl kwd">data.frame</span>(
  <span class="hl str">&quot;Name&quot;</span> = <span class="hl kwd">c</span>(<span class="hl str">&quot;Mean&quot;</span>, <span class="hl str">&quot;SD&quot;</span>, <span class="hl str">&quot;it&quot;</span>, <span class="hl str">&quot;Start&quot;</span>),
  <span class="hl str">&quot;Value&quot;</span> = <span class="hl kwd">c</span>(
    <span class="hl kwd">decimal</span>(chain.mu, dec), 
    <span class="hl kwd">decimal</span>(chain.sd, dec), 
    <span class="hl kwd">decimal</span>(<span class="hl kwd">length</span>(chain), 0),
    <span class="hl kwd">decimal</span>(chain[1], dec)
  )
)
tg &lt;- <span class="hl kwd">tableGrob</span>(table)

#plot theta_i versus <span class="hl kwd">i</span> (iterations)
plot &lt;- <span class="hl kwd">ggplot</span>(df, <span class="hl kwd">aes</span>(x=i, y=theta.i))+
  <span class="hl kwd">geom_line</span>(alpha=0.4)

<span class="hl kwd">grid.arrange</span>(plot, tg, widths=<span class="hl kwd">c</span>(4,1)
             ,top = <span class="hl kwd">textGrob</span>(main, vjust = .5, gp = <span class="hl kwd">gpar</span>(fontface = <span class="hl str">&quot;bold&quot;</span>, cex = 1.1))
                             )
}
```

```{r p2aRESULT, fig.height=2}
Y.A &lt;- <span class="hl kwd">c</span>(125, 18, 20, 34)

<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroFix</span>(211, 10000, Y.A, func_driver1.Uniform), <span class="hl str">&quot;<span class="hl kwd">Uniform</span>(0,1)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroDyn</span>(212, 10000, Y.A, func_driver2.Norm.sd.01),   <span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.01)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroDyn</span>(213, 10000, Y.A, func_driver3.Norm.sd.1 ),   <span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.10)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroDyn</span>(214, 10000, Y.A, func_driver4.Norm.sd.5 ),   <span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.50)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroFix</span>(215, 10000, Y.A, func_driver5.Norm.mu.4sd.5),<span class="hl str">&quot;<span class="hl kwd">Normal</span>(0.40, 0.10)&quot;</span>)
```

\newpage  
<span class="hl com">## Problem 2b  </span>
Repeat 2a <span class="hl kwa">for</span> $Y = (14, 0, 1, 5)$  
```{r p2bRESULT, fig.height=2}
Y.B &lt;- <span class="hl kwd">c</span>(14, 0, 1, 5)

<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroFix</span>(221, 10000, Y.B, func_driver1.Uniform), <span class="hl str">&quot;<span class="hl kwd">Uniform</span>(0,1)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroDyn</span>(222, 10000, Y.B, func_driver2.Norm.sd.01),   <span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.01)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroDyn</span>(223, 10000, Y.B, func_driver3.Norm.sd.1 ),   <span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.10)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroDyn</span>(224, 10000, Y.B, func_driver4.Norm.sd.5 ),   <span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.50)&quot;</span>)
<span class="hl kwd">func_problem2ABC</span>(<span class="hl kwd">func_MetroFix</span>(225, 10000, Y.B, func_driver5.Norm.mu.4sd.5),<span class="hl str">&quot;<span class="hl kwd">Normal</span>(0.40, 0.10)&quot;</span>)
```

<span class="hl com">## Problem 2c  </span>
Compute both the posterior mean and standard deviation <span class="hl kwa">for</span> both data sets.  
Compare to results from the previous problem.  

In problem 1 the means were similar, but <span class="hl kwa">in</span> problem 2 the means vary depending on the driver.  Some of the means <span class="hl kwa">in</span> problem 2 are close to the means <span class="hl kwa">in</span> problem 1.  

\newpage  
<span class="hl com">## Problem 2d  </span>

```{r p2.func_Metroinfo}
func_Metroinfo &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, m, Y, driver, metro.func){
chain &lt;- <span class="hl kwd">metro.func</span>(startseed, m, Y, driver)
it &lt;- <span class="hl kwd">length</span>(chain)
chain.mu &lt;- <span class="hl kwd">mean</span>(chain)
chain.sd &lt;- <span class="hl kwd">sd</span>(chain)
chain.se &lt;- chain.sd/<span class="hl kwd">sqrt</span>(it)
vec &lt;-<span class="hl kwd">c</span>(chain.mu, chain.sd, chain.se)
<span class="hl kwd">return</span>(vec)
}
```

```{r p2.func_20chains}
func_20metrochains &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(Y, driver, metro.func){
print.Y &lt;- <span class="hl kwd">paste</span>(Y, collapse=<span class="hl str">&quot;,&quot;</span>)
cnames &lt;- <span class="hl kwd">c</span>(<span class="hl str">&quot;Mean&quot;</span>, <span class="hl str">&quot;SD&quot;</span>, <span class="hl str">&quot;SE&quot;</span>)
info.20chain &lt;- <span class="hl kwd">mapply</span>( func_Metroinfo
                       , startseed=<span class="hl kwd">c</span>(1:20)
                       , m =<span class="hl kwd">rep</span>(10000, 20)
                       , Y=<span class="hl kwd">rep</span>(<span class="hl kwd">list</span>(Y), 20)
                       , driver=<span class="hl kwd">rep</span>(<span class="hl kwd">list</span>(driver), 20)
                       , metro.func=<span class="hl kwd">rep</span>(<span class="hl kwd">list</span>(metro.func), 20)
                      )
info.20chain &lt;- <span class="hl kwd">t</span>(info.20chain)
<span class="hl kwd">colnames</span>(info.20chain) &lt;- cnames
info.20chain
}
```

```{r p2dRESULT20chains}
Y.D &lt;- <span class="hl kwd">c</span>(125, 18, 20, 34)

d1 &lt;- <span class="hl kwd">func_20metrochains</span>(Y.D, func_driver1.Uniform,      func_MetroFix)
d2 &lt;- <span class="hl kwd">func_20metrochains</span>(Y.D, func_driver2.Norm.sd.01,    func_MetroDyn)
d3 &lt;- <span class="hl kwd">func_20metrochains</span>(Y.D, func_driver3.Norm.sd.1,     func_MetroDyn)
d4 &lt;- <span class="hl kwd">func_20metrochains</span>(Y.D, func_driver4.Norm.sd.5,     func_MetroDyn)
d5 &lt;- <span class="hl kwd">func_20metrochains</span>(Y.D, func_driver5.Norm.mu.4sd.5, func_MetroFix)

table2d &lt;- <span class="hl kwd">cbind</span>(d1, d2, d3, d4, d5)

print.Y.D &lt;- <span class="hl kwd">paste</span>(Y.D, collapse=<span class="hl str">&quot;,&quot;</span>)

knitr::<span class="hl kwd">kable</span>(table2d, digits=4, booktabs=<span class="hl kwa">TRUE</span>, <span class="hl str">'latex'</span>
             , caption=<span class="hl kwd">paste</span>(<span class="hl str">&quot;20 Chains <span class="hl kwa">for</span> Y=(&quot;</span>,print.Y.D, <span class="hl str">&quot;) with Different Drivers&quot;</span>)
             ) %&gt;%
  kableExtra::<span class="hl kwd">kable_styling</span>(latex_options=<span class="hl kwd">c</span>(<span class="hl str">&quot;hold_position&quot;</span>, <span class="hl str">&quot;scale_down&quot;</span>) ) %&gt;% 
  kableExtra::<span class="hl kwd">add_header_above</span>(<span class="hl kwd">c</span>( <span class="hl str">&quot;<span class="hl kwd">Uniform</span>(0, 1)&quot;</span> =3
                                 ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.01)&quot;</span>=3
                                 ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.10)&quot;</span>=3
                                 ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.50&quot;</span>=3
                                 ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(0.40, 0.10)&quot;</span>=3
                                ))
```

```{r p2dRESULTavgsd.vs.se}
sd.of.avgs &lt;- <span class="hl kwd">c</span>(
   <span class="hl kwd">sd</span>(table2d[,1])
  ,<span class="hl kwd">sd</span>(table2d[,4])
  ,<span class="hl kwd">sd</span>(table2d[,7])
  ,<span class="hl kwd">sd</span>(table2d[,10])
  ,<span class="hl kwd">sd</span>(table2d[,13])
  )

avg.of.se &lt;- <span class="hl kwd">c</span>(
   <span class="hl kwd">mean</span>(table2d[,3])
  ,<span class="hl kwd">mean</span>(table2d[,6])
  ,<span class="hl kwd">mean</span>(table2d[,9])
  ,<span class="hl kwd">mean</span>(table2d[,12])
  ,<span class="hl kwd">mean</span>(table2d[,15])
  )

driver.name &lt;- <span class="hl kwd">c</span>(
  <span class="hl str">&quot;<span class="hl kwd">Uniform</span>(0,1)&quot;</span>
  ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.01)&quot;</span>
  ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.10)&quot;</span>
  ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(theta.i, 0.50)&quot;</span>
  ,<span class="hl str">&quot;<span class="hl kwd">Normal</span>(0.40, 0.10)&quot;</span>
)


table2d.sdse &lt;- <span class="hl kwd">cbind</span>(sd.of.avgs, avg.of.se)
<span class="hl kwd">rownames</span>(table2d.sdse) &lt;- driver.name

knitr::<span class="hl kwd">kable</span>(table2d.sdse, <span class="hl str">'latex'</span>, booktabs=TRUE
             , caption=<span class="hl kwd">paste</span>(<span class="hl str">&quot;SD of Average theta's versus Average SE&quot;</span>)
             )  %&gt;%
    kableExtra::<span class="hl kwd">kable_styling</span>(latex_options=<span class="hl str">&quot;hold_position&quot;</span>)
```

Similar to problem 1, it appears that our estimation of the variation <span class="hl kwa">in</span> the mean of theta is lower than the actual variation between the means.   
 

\newpage  
<span class="hl com"># Problem 3  </span>

<span class="hl com">## Problem 3a  </span>
Consider the 1-way variance components model
$$Y_{ij} = \theta_i + \epsilon_{ij}$$ 
where $Y_{ij}$ is the $j$th observation from the $i$th group, $\theta_i$ is the effect, $\epsilon_{ij}$=error,
$i=1, ..., K$ and $j=1, ..., J$.
It is assume that $\epsilon_{ij} \stackrel{\text{iid}}{\sim} \mathcal{N}(0, \sigma^2_{\epsilon})$
and $\theta_i \stackrel{\text{iid}}{\sim} \mathcal{N}(\mu, \sigma^2_{\theta})$.
Under the prior specification $<span class="hl kwd">p</span>(\sigma^2_{\epsilon}, \sigma^2_{\theta}, \mu) =$
$<span class="hl kwd">p</span>(\sigma^2_{\epsilon})<span class="hl kwd">p</span>(\sigma^2_{\theta})<span class="hl kwd">p</span>(\mu)$, with
$<span class="hl kwd">p</span>(\sigma_\theta^2) = \text{InverseGamma}(a_1, b_1)$, 
$<span class="hl kwd">p</span>(\sigma_\epsilon^2) = \text{InverseGamma}(a_2, b_2)$, and
$<span class="hl kwd">p</span>(\mu) = \mathcal{N}(\mu_0, \sigma^2_0)$.  
Let $\overline{Y}_i = \frac{1}{J} \sum_{j=1}^J Y_{ij}$ and $\theta = (theta_1, \cdots, \theta_k)$.  
Show the following: 

$$
\begin{aligned}
<span class="hl kwd">p</span>(\mu, \sigma^2_\epsilon, \sigma^2_\theta) &amp; = <span class="hl kwd">p</span>(\mu) <span class="hl kwd">p</span>(\sigma^2_\theta) <span class="hl kwd">p</span>(\sigma^2_\epsilon)
\\
&amp; = \mathcal{N}(\mu_0, \sigma^2_0) \text{IG}(a_1, b_1) \text{IG}(a_2, b_2)
\\
&amp;= \left[
\frac{1}{\sqrt{2 \<span class="hl kwa">pi</span>} \  \sigma_0} \exp \left\{ - \frac{1}{2} \frac{ (\mu - \mu_0)^2}{\sigma_0^2} \right\}
\right]
\cdot 
\left[
(\sigma^2_\theta)^{a_1 - 1} \exp \left\{ -b_1 \sigma^2_\theta \right\} 
\right]^{-1}
\cdot 
\left[
(\sigma^2_\epsilon)^{a_2 - 1} \exp \left\{ -b_2 \sigma^2_\epsilon \right\} 
\right]^{-1}
\\[0.5ex]
&amp; \propto   
\sigma_\theta^{-<span class="hl kwd">2</span>(a_1 - 1)} \cdot 
\sigma_\epsilon^{-<span class="hl kwd">2</span>(a_2 - 1)} \cdot 
\exp \left\{
-\frac{1}{2} \frac{(\mu - \mu_0)^2}{\sigma_0^2} + b_1 \sigma^2_\theta + b_2 \sigma^2_\epsilon 
\right\}
\\[2ex]
<span class="hl kwd">p</span>(\mu, \theta, \sigma^2_\theta, \sigma^2_\epsilon \mid Y) &amp; \propto <span class="hl kwd">p</span>(Y \mid \mu, \theta, \sigma^2_\theta, \sigma^2_\epsilon ) \cdot <span class="hl kwd">p</span>(\theta \mid \mu, \sigma^2_\theta, \sigma^2_\epsilon) \cdot <span class="hl kwd">p</span>( \mu, \sigma^2_\theta, \sigma^2_\epsilon)
\\
&amp; = \left[ \prod_{i=1}^K \prod_{j=1}^J <span class="hl kwd">\left</span>( <span class="hl kwd">p</span>(y_{ij}) \sim \mathcal{N}(\theta_i, \sigma^2_\epsilon) \right) \right]  \cdot 
\left[ \prod_{i=1}^K <span class="hl kwd">\left</span>( <span class="hl kwd">p</span>(\theta_i) \sim \mathcal{N}(\mu, \sigma^2_\theta) \right) \right] 
 \cdot \prod_{i=1}^K <span class="hl kwd">p</span>( \mu, \sigma^2_\theta, \sigma^2_\epsilon)
\\[0.5ex]
&amp; = \left[ 
\sigma_\epsilon^{-(KJ)} \cdot \exp \left\{ - \frac{1}{2} \frac{\sum_{i=1}^K \sum_{j=1}^<span class="hl kwd">J</span> (y_{ij}  - \theta_i)^2}
{\sigma^2_\epsilon} \right\} \right] 
\\[0.5ex]
&amp; \quad \cdot \left[\sigma_\theta^{-K} \exp \left\{ - \frac{1}{2} \frac{\sum_{i=1}^<span class="hl kwd">K</span> (\theta_i - \mu)^2}
{\sigma^2_\theta } \right\} \right] 
\\[0.5ex]
&amp; \quad \cdot \left[ 
\sigma_\theta^{-<span class="hl kwd">2K</span>(a_1 - 1)} \cdot 
\sigma_\epsilon^{-<span class="hl kwd">2K</span>(a_2 - 1)} \cdot 
\exp \left\{ K <span class="hl kwd">\left</span>( 
-\frac{1}{2} \frac{(\mu - \mu_0)^2}{\sigma_0^2} + b_1 \sigma^2_\theta + b_2 \sigma^2_\epsilon 
\right) \right\} \right] 
\end{aligned} 
$$

\newpage  
### Problem <span class="hl kwd">3a</span>(1) 
$$
\begin{aligned}
<span class="hl kwd">p</span>(\mu \mid \theta, \sigma^2_{\epsilon}, \sigma^2_{\theta}, Y) 
&amp;\propto  =  \exp \left\{ - \frac{1}{2} \frac{\sum_{i=1}^<span class="hl kwd">K</span> (\theta_i - \mu)^2}
{\sigma^2_\theta } \right\}  \cdot 
\exp \left\{ K <span class="hl kwd">\left</span>( 
-\frac{1}{2} \frac{(\mu - \mu_0)^2}{\sigma_0^2} 
\right) \right\} 
\\[0.5ex]
&amp; =  \mathcal{N} <span class="hl kwd">\left</span>( 
\frac{ \sigma_\theta^2 \mu_0 + \sigma_0^2 \sum \theta_i}{\sigma^2_\theta + K \sigma^2_0}
, \ 
\frac{ \sigma^2_\theta \sigma^2_0}{\sigma^2_\theta + K \sigma^2_0}
\right)
\end{aligned}
$$

### Problem <span class="hl kwd">3a</span>(2)  
$$
\begin{aligned}
<span class="hl kwd">p</span>(\theta_i \mid \mu, \sigma^2_\epsilon, \sigma^2_\theta, Y) &amp; \propto 
\cdot \exp \left\{ - \frac{1}{2} \frac{\sum_{i=1}^K \sum_{j=1}^<span class="hl kwd">J</span> (y_{ij}  - \theta_i)^2}
{\sigma^2_\epsilon} \right\}  \cdot 
\exp \left\{ - \frac{1}{2} \frac{\sum_{i=1}^<span class="hl kwd">K</span> (\theta_i - \mu)^2}
{\sigma^2_\theta } \right\} 
\\[0.5ex]
&amp; =  \mathcal{N} <span class="hl kwd">\left</span>( 
\frac{J\sigma^2_\theta}{J\sigma^2_\theta + \sigma_\epsilon^2} \cdot \overline{Y}_i
+ 
\frac{\sigma^2_\epsilon}{J\sigma^2_\theta + \sigma_\epsilon^2} \cdot \mu
, \ \ \ 
\frac{\sigma^2_\theta \sigma^2_\epsilon}{J\sigma^2_\theta + \sigma_\epsilon^2}
\right) 
\end{aligned}
$$

### Problem <span class="hl kwd">3a</span>(3)  
$$
\begin{aligned}
<span class="hl kwd">p</span>(\sigma^2_\epsilon \mid \mu, \theta, \sigma^2_\theta, Y)   &amp; \propto 
 = 
\sigma_\epsilon^{-(KJ)} \cdot \exp \left\{ - \frac{1}{2} \frac{\sum_{i=1}^K \sum_{j=1}^<span class="hl kwd">J</span> (y_{ij}  - \theta_i)^2}
{\sigma^2_\epsilon} \right\}  
 \cdot 
\sigma_\epsilon^{-<span class="hl kwd">2K</span>(a_2 - 1)} \cdot 
\exp \left\{ K <span class="hl kwd">\left</span>( 
 b_2 \sigma^2_\epsilon 
\right) \right\} 
\\[0.5ex]
&amp; =\text{IG}
<span class="hl kwd">\left</span>(
a_2 + \frac{KJ}{2}, \ 
b_2 + \frac{1}{2} \sum_{i=1}^K \sum_{j=1}^<span class="hl kwd">J</span> (Y_{ij} - \theta_i)^2
\right)
\end{aligned}
$$

### Problem <span class="hl kwd">3a</span>(4) 
$$
\begin{aligned}
<span class="hl kwd">p</span>(\sigma^2_\theta \mid \mu, \theta, \sigma^2_\epsilon, Y)  &amp; \propto 
\sigma_\theta^{-K} \exp \left\{ - \frac{1}{2} \frac{\sum_{i=1}^<span class="hl kwd">K</span> (\theta_i - \mu)^2}
{\sigma^2_\theta } \right\} 
 \cdot  
\sigma_\theta^{-<span class="hl kwd">2K</span>(a_1 - 1)} \cdot 
\exp \left\{ K <span class="hl kwd">\left</span>( 
 b_1 \sigma^2_\theta 
\right) \right\} 
\\[0.5ex]
&amp; = \text{IG}
<span class="hl kwd">\left</span>(
a_1 + \frac{K}{2}
, \ 
b_1 + \frac{1}{2} \sum_{i=1}^<span class="hl kwd">K</span>  (\theta_i - \mu)^2
\right)
\end{aligned}
$$

\newpage  
<span class="hl com">## Problem 3b  </span>
Run the Gibbs sampler <span class="hl kwa">for</span> the data below.  
```{r p3b.data, eval=<span class="hl kwa">TRUE</span>}
j1 &lt;- <span class="hl kwd">c</span>( 7.298,  3.846,  2.434,  9.566,  7.990)
j2 &lt;- <span class="hl kwd">c</span>( 5.220,  6.556,  0.608, 11.788, -0.892)
j3 &lt;- <span class="hl kwd">c</span>( 0.110, 10.386, 13.434,  5.510,  8.166)
j4 &lt;- <span class="hl kwd">c</span>( 2.212,  4.852,  7.092,  9.288,  4.980)
j5 &lt;- <span class="hl kwd">c</span>( 0.282,  9.014,  4.458,  9.446,  7.198)
j6 &lt;- <span class="hl kwd">c</span>( 1.722,  4.782,  8.106,  0.758,  3.758)

Y &lt;- <span class="hl kwd">cbind</span>(j1, j2, j3, j4, j5, j6)
y_j. &lt;- <span class="hl kwd">apply</span>(Y, 2, mean)

<span class="hl kwd">rbind</span>(Y, <span class="hl kwd">c</span>(<span class="hl kwd">rep</span>(<span class="hl str">&quot; &quot;</span>, 6)), y_j.)
<span class="hl kwd">paste</span>(<span class="hl str">&quot;y_..=&quot;</span>, <span class="hl kwd">mean</span>(Y))

```

Use one chain of length 75,000.
Take $<span class="hl kwd">p</span>(\mu) =\mathcal{N}(0, 10^{12})$,  $<span class="hl kwd">p</span>(\sigma^2_\epsilon) = <span class="hl kwd">IG</span>(0, 0)$, and $<span class="hl kwd">p</span>(\sigma^2_\theta) = <span class="hl kwd">IG</span>(1, 1)$.
For each $\theta_i$, <span class="hl kwa">for</span> $\sigma_\epsilon$, and <span class="hl kwa">for</span> $\theta_\theta$, plot the simulated value at iteration $j$ versus $j$.
Summarize each posterior marginal.  

```{r p3b.func_gibbsdf}
func_gibbsdf &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, it, mu.o, sig2.o, a1, b1, a2, b2, Y){
<span class="hl kwd">set.seed</span>(startseed)
J &lt;- <span class="hl kwd">dim</span>(Y)[2] #ROW, observations
K &lt;- <span class="hl kwd">dim</span>(Y)[1] #COLUMN, group
Y.col &lt;- <span class="hl kwd">apply</span>(Y, 2, mean) #col means
sig.o &lt;- <span class="hl kwd">sqrt</span>(sig2.o)
chain.mu &lt;- <span class="hl kwd">c</span>()
chain.sig2.0 &lt;- <span class="hl kwd">c</span>()
chain.sig2.e &lt;- <span class="hl kwd">c</span>()
chain.theta &lt;- <span class="hl kwd">matrix</span>(0, nrow=it, ncol=K)

<span class="hl com">#Iteration ONE - STARTING VALUES </span>
mu &lt;- <span class="hl kwd">rnorm</span>(1, mu.o, sig.o) #generate \mu
sig2.0 &lt;- <span class="hl kwd">rinvgamma</span>(1, a1, b1) #generate \sigma_\theta
sig2.e &lt;- <span class="hl kwd">rinvgamma</span>(1, a2, b2) #generate \sigma_\epsilon 
theta &lt;- <span class="hl kwd">rnorm</span>(K, mu, <span class="hl kwd">sqrt</span>(sig2.0)) #generate \theta = (\theta_1, ..., theta_K)
chain.mu[1] &lt;- mu
chain.sig2.0[1] &lt;- sig2.0
chain.sig2.e[1] &lt;- sig2.e
chain.theta[1,] &lt;- theta 

<span class="hl com">#ITERATION TWO+ </span>
<span class="hl kwd"><span class="hl kwa">for</span></span> (l <span class="hl kwa">in</span> 2:it){
  <span class="hl com">#values <span class="hl kwa">for</span> respective distributions </span>
  mean.mu &lt;- (sig2.0 * mu.o + sig2.o *<span class="hl kwd">sum</span>(theta)) / (sig2.0 + K * sig2.o)
  sig2.mu &lt;- (sig2.0*sig2.o) / (sig2.0 + K * sig2.o)
  A.sig2.0 &lt;- a1 + K/2
  B.sig2.0 &lt;- b1 + .5 * <span class="hl kwd">sum</span>((theta - mu)^2)
  A.sig2.e &lt;- a2 + (K*J)/2
  B.sig2.e &lt;- b2 + .5 *<span class="hl kwd">sum</span>( (Y - <span class="hl kwd">matrix</span>(theta, K, J, byrow=<span class="hl kwa">TRUE</span>))^2 )
  mean.theta &lt;- Y.col * (J * sig2.0 )/(J * sig2.0 + sig2.e) + mu * (sig2.e)/(J * sig2.0 + sig2.e)
  sig2.theta &lt;- (sig2.0 * sig2.e)/(J * sig2.0 + sig2.e)
  
  <span class="hl com">#new values </span>
  mu &lt;- <span class="hl kwd">rnorm</span>(1, mean.mu, <span class="hl kwd">sqrt</span>(sig2.mu))
  sig2.0 &lt;- <span class="hl kwd">rinvgamma</span>(1, A.sig2.0, B.sig2.0)
  sig2.e &lt;- <span class="hl kwd">rinvgamma</span>(1, A.sig2.e, B.sig2.e)
  theta &lt;- <span class="hl kwd">rnorm</span>(K, mean.theta, <span class="hl kwd">sqrt</span>(sig2.theta))
  
  <span class="hl com">#put new values into chains</span>
  chain.mu[l] &lt;- mu
  chain.sig2.0[l] &lt;- sig2.0
  chain.sig2.e[l] &lt;- sig2.e
  chain.theta[l,] &lt;- theta 
}

df.chain &lt;- <span class="hl kwd">data.frame</span>(
   <span class="hl str">&quot;iteration&quot;</span>= <span class="hl kwd">c</span>(1:it)
  ,<span class="hl str">&quot;mu&quot;</span> = chain.mu
  ,<span class="hl str">&quot;sig2.theta&quot;</span> = chain.sig2.0
  ,<span class="hl str">&quot;sig2.epsilon&quot;</span> = chain.sig2.e
  ,<span class="hl str">&quot;theta.1&quot;</span> = chain.theta[,1]
  ,<span class="hl str">&quot;theta.2&quot;</span> = chain.theta[,2]
  ,<span class="hl str">&quot;theta.3&quot;</span> = chain.theta[,3]
  ,<span class="hl str">&quot;theta.4&quot;</span> = chain.theta[,4]
  ,<span class="hl str">&quot;theta.5&quot;</span> = chain.theta[,5]
  ,<span class="hl str">&quot;theta.6&quot;</span> = chain.theta[,5]
)

<span class="hl kwd">return</span>(df.chain)
}

```

```{r 3b.func_plotchain}
func_plotchain &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(df.chain,throw.out,  c, yval.tex){
df.chain &lt;- df.chain[throw.out:<span class="hl kwd">nrow</span>(df.chain), ] #throw out first _ values
yval &lt;- df.chain[, c]
post.mean &lt;- <span class="hl kwd">mean</span>(yval)
xname &lt;- <span class="hl kwd">colnames</span>(df.chain)[1]
<span class="hl kwd">ggplot</span>(df.chain, <span class="hl kwd">aes</span>(x=iteration, y=df.chain[,c])) + <span class="hl kwd">geom_line</span>(alpha=0.4)+
  <span class="hl kwd">ggtitle</span>(<span class="hl kwd">TeX</span>(<span class="hl kwd">paste</span>(yval.tex ,<span class="hl str">&quot;versus iteration&quot;</span>)))+ <span class="hl kwd">ylab</span>(<span class="hl kwd">TeX</span>(yval.tex)) + <span class="hl kwd">xlab</span>(<span class="hl str">&quot;Iteration&quot;</span>)+
  <span class="hl kwd">annotate</span>(<span class="hl str">'text'</span>, x=<span class="hl kwd">mean</span>(df.chain$iteration), y=<span class="hl kwa">Inf</span>, 
           label=<span class="hl kwd">paste</span>(<span class="hl str">&quot;Mean=&quot;</span>,<span class="hl kwd">decimal</span>(post.mean, dec)), vjust=2, fontface=<span class="hl str">&quot;bold&quot;</span>)
}
```

```{r p3b.func_problem3b}

func_problem3b &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, it, mu.o, sig2.o, a1, b1, a2, b2, Y, throw.out){
df.chain &lt;- <span class="hl kwd">func_gibbsdf</span>(startseed, it, mu.o, sig2.o, a1, b1, a2, b2, Y)
plot.mu &lt;-          <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 2, <span class="hl str">&quot;$\\mu$&quot;</span>)
plot.sig2theta &lt;-   <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 3, <span class="hl str">&quot;$\\sigma^2_{\\theta}$&quot;</span>)
plot.sig2epsilon &lt;- <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 4, <span class="hl str">&quot;$\\sigma^2_{\\epsilon}$&quot;</span>)
plot.theta1 &lt;-      <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 5, <span class="hl str">&quot;$\\theta_1$&quot;</span>)
plot.theta2 &lt;-      <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 6, <span class="hl str">&quot;$\\theta_2$&quot;</span>)
plot.theta3 &lt;-      <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 7, <span class="hl str">&quot;$\\theta_3$&quot;</span>)
plot.theta4 &lt;-      <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 8, <span class="hl str">&quot;$\\theta_4$&quot;</span>)
plot.theta5 &lt;-      <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 9, <span class="hl str">&quot;$\\theta_5$&quot;</span>)
plot.theta6 &lt;-      <span class="hl kwd">func_plotchain</span>(df.chain, throw.out, 10, <span class="hl str">&quot;$\\theta_6$&quot;</span>)

gs &lt;- <span class="hl kwd">list</span>(  plot.mu
              , plot.sig2theta
              , plot.sig2epsilon
              , plot.theta1
              , plot.theta2
              , plot.theta3
              , plot.theta4
              , plot.theta5
              , plot.theta6)

#gs &lt;- <span class="hl kwd">list</span>(plot.theta1, plot.theta2, plot.theta3)
<span class="hl kwd">grid.arrange</span>(grobs=gs, nrow=3, ncol=3
             , top = <span class="hl kwd">textGrob</span>(<span class="hl kwd">paste</span>(<span class="hl str">&quot;Chains versus Iterations, throwing out first&quot;</span>, throw.out,<span class="hl str">&quot;values on&quot;</span>, it, <span class="hl str">&quot;chain&quot;</span>), vjust = .5, gp = <span class="hl kwd">gpar</span>(fontface = <span class="hl str">&quot;bold&quot;</span>, cex = 1.2))
            )
}
```

Cannot use $a_1, b_1 = 0$, otherwise $\sigma^2_\theta = \infty$, resulting <span class="hl kwa">in</span> N/A so will use 0.01 instead.  
```{r p3bRESULT, fig.height=8}
it &lt;-75000
<span class="hl com">#prior <span class="hl kwa">for</span> mu</span>
mu.o &lt;- 0
sig2.o &lt;- 10^12
<span class="hl com">#prior <span class="hl kwa">for</span> sig2.theta</span>
a1 &lt;- .01
b1 &lt;- .01
<span class="hl com">#prior <span class="hl kwa">for</span> sig2.epsilon </span>
a2 &lt;- 1
b2 &lt;- 1

Y &lt;- <span class="hl kwd">cbind</span>(j1, j2, j3, j4, j5, j6)
startseed &lt;- 32

<span class="hl kwd">func_problem3b</span>(startseed, it, mu.o, sig2.o, a1, b1, a2, b2, Y, 1000)
```

\newpage  
<span class="hl com">## Problem 3c </span>
Repeat 3b using the prior specification $<span class="hl kwd">p</span>(\mu) = \mathcal{N}(0, 10^{12})$, $<span class="hl kwd">p</span>(\sigma_\epsilon^2) = <span class="hl kwd">IG</span>(0, 0)$, and
$<span class="hl kwd">p</span>(\sigma^2_\theta) = <span class="hl kwd">IG</span>(0, 0)$.  Does this specification violate the Hobart-Casella conditions? 
Describe what happens to the Gibbs sampler chain <span class="hl kwa">in</span> this case.  

This violates the Hobart-Casella conditions.  If left at zero, the result will <span class="hl str">&quot;blow up&quot;</span> (i.e., the chains are full of <span class="hl kwa">NA</span>).  
Cannot use $a_1, b_1, a_2, b_2 = 0$, otherwise $\sigma^2_\theta = \sigma^2_\epsilon  = \infty$, resulting <span class="hl kwa">in</span> N/A so will use 0.01 instead.   
```{r p3cRESULT, fig.height=8}
it &lt;-75000
<span class="hl com">#prior <span class="hl kwa">for</span> mu</span>
mu.o &lt;- 0
sig2.o &lt;- 10^12
<span class="hl com">#prior <span class="hl kwa">for</span> sig2.theta</span>
a1 &lt;- .01
b1 &lt;- .01
<span class="hl com">#prior <span class="hl kwa">for</span> sig2.epsilon </span>
a2 &lt;- .01
b2 &lt;- .01

Y &lt;- <span class="hl kwd">cbind</span>(j1, j2, j3, j4, j5, j6)
startseed &lt;- 32

<span class="hl kwd">func_problem3b</span>(startseed, it, mu.o, sig2.o, a1, b1, a2, b2, Y, 1000)
```

\newpage 
<span class="hl com"># Problem 5  </span>
Suppose that $X$ and $Y$ have exponential conditional distributions restricted over the interval $(0, B)$, i.e. 
$<span class="hl kwd">p</span>(x \mid y) \propto y \exp \left\{ -yx \right\}$ <span class="hl kwa">for</span> $0 &lt; x &lt; B &lt; \infty$ and 
$<span class="hl kwd">p</span>(y \mid x) \propto x \exp \left\{ -xy \right\}$ <span class="hl kwa">for</span> $0 &lt; y &lt; B &lt; \infty$, where $B$ is known constant.  

<span class="hl com">## Problem 5a  </span>
Take $m=1$ and $B=3$.  Run the data augmentation algorithm using these conditionals.
(Hist: Reject the exponential deviates that lie outside $(0, B)$).
Obtain the marginal <span class="hl kwa">for</span> $x$ using the mixture of conditionals $<span class="hl kwd">p</span>(x \mid y)$, mixed over the simulated $y$ deviates <span class="hl kwa">in</span> your chain.  

```{r p5.func_gibbs.prob5A}
func_gibbs.p5 &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(B, it){
  x &lt;- <span class="hl kwd">c</span>(<span class="hl kwd">rep</span>(B+1, it))
  y &lt;- <span class="hl kwd">c</span>(<span class="hl kwd">rep</span>(B+1, it))
  x[1] &lt;- <span class="hl kwd">runif</span>(1, 0, B)
  y[1] &lt;- <span class="hl kwd">runif</span>(1, 0, B)
  <span class="hl kwd"><span class="hl kwa">for</span></span>(k <span class="hl kwa">in</span> 2:it) {
    <span class="hl kwd"><span class="hl kwa">while</span></span>(x[k] &gt; B){ x[k]&lt;-<span class="hl kwd">rexp</span>(1,y[k-1]) }
    <span class="hl kwd"><span class="hl kwa">while</span></span>(y[k] &gt; B){ y[k]&lt;-<span class="hl kwd">rexp</span>(1,x[k-1]) }
  }
  df &lt;- <span class="hl kwd">as.data.frame</span>(<span class="hl kwd">cbind</span>(x, y))
<span class="hl kwd">return</span>(df)
}

marginal &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(k, rate){
  (1-<span class="hl kwd">exp</span>(-rate*k))/(k)
}

func_marginal &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(k, rate){
  <span class="hl kwd">marginal</span>(k, rate)/rate #to normalize to 0 to 1
}

func_problem5A &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, B, it){
  <span class="hl kwd">set.seed</span>(startseed)
  df &lt;- <span class="hl kwd">func_gibbs.p5</span>(B, it)

true.cdf &lt;-<span class="hl kwd">stat_function</span>(fun = func_marginal, args = B, lwd = 1, linetype=<span class="hl str">&quot;solid&quot;</span>, col=<span class="hl str">&quot;maroon&quot;</span>)

plot.x &lt;- <span class="hl kwd">ggplot</span>(df, <span class="hl kwd">aes</span>(x)) + <span class="hl kwd">xlim</span>(0, B)+
  <span class="hl kwd">geom_histogram</span>(<span class="hl kwd">aes</span>(y=..density..), alpha=0.4) + 
  true.cdf +<span class="hl kwd">xlab</span>(<span class="hl str">&quot;X Chain Values&quot;</span>)+
  <span class="hl kwd">ggtitle</span>(<span class="hl str">&quot;Marginal of X: Histogram and True Curve&quot;</span>)

plot.y &lt;- <span class="hl kwd">ggplot</span>(df, <span class="hl kwd">aes</span>(y)) + <span class="hl kwd">xlim</span>(0, B)+
  <span class="hl kwd">geom_histogram</span>(<span class="hl kwd">aes</span>(y=..density..), alpha=0.4) + 
  true.cdf +<span class="hl kwd">xlab</span>(<span class="hl str">&quot;Y Chain Values&quot;</span>)+
  <span class="hl kwd">ggtitle</span>(<span class="hl str">&quot;Marginal of Y: Histogram and True Curve&quot;</span>)

<span class="hl kwd">grid.arrange</span>(plot.x, plot.y, nrow=1)

}
```


```{r p5aRESULTS, message=<span class="hl kwa">FALSE</span>, warning=<span class="hl kwa">FALSE</span>}
<span class="hl kwd">func_problem5A</span>(510, 3, 100000)
```



<span class="hl com">## Problem 5b  </span>
Show that the marginal <span class="hl kwa">for</span> $x$ is proportional to $(1 - \exp\left\{ -Bx \right\})/x$.
Compare your results <span class="hl kwa">in</span> 5a to this curve.  

$$
\begin{aligned}
p_{X \mid Y}(x \mid y) &amp; = ye^{-yx}
\\
p_{X}(x) &amp; \propto \int_{0}^B e^{-yx} dy 
\\[0.5ex]
&amp; = \frac{1}{x} \int_{0}^B xe^{-xy} dy 
\\[0.5ex]
&amp; = \frac{1}{x} \Big[ - e^{-xy}
\Big]_{y=0}^{y=B} 
\\[0.5ex]
&amp; = \frac{1}{x} <span class="hl kwd">\Big</span>(
\left[ -e^{-Bx} \right]  - \left[ -e^{-0 \cdot x} \right] 
\Big)
\\[0.5ex]
&amp; = \frac{1}{x} <span class="hl kwd">\Big</span>( - e^{-Bx} + 1 \Big) 
\\[0.5ex]
&amp; = \frac{ 1 - e^{-Bx} }{x}
\\[1.5ex]
p_{X}(x) &amp; \propto \frac{ 1 - e^{-Bx} }{x}
\end{aligned}
$$
 
See above <span class="hl kwa">for</span> the histogram of the marginals with the curves.  Note the curves are normalized by dividing by $B$ so that both the histogram density and the curve are on scale of 0 to 1.  The curve matches the histogram very well.  


\newpage   

<span class="hl com">## Problem 5c </span>
Repeat 5a and 5b using $B= \infty$.  Describe what happens.  Is the marginal <span class="hl kwa">for</span> $x$ a proper density <span class="hl kwa">in</span> this case?  

$$
\lim_{B \to \infty} \frac{ 1 - e^{-Bx} }{x} = \frac{ 1 - \lim_{B \to \infty} e^{-Bx}}{x}  = \frac{1}{x} 
$$

This is not a proper marginal.   
$$
\int_{0}^B \frac{1}{x} dx = <span class="hl kwd">\ln</span>(x) \Big|_{0}^B = <span class="hl kwd">\ln</span>(B) - <span class="hl kwd">\ln</span>(0) = <span class="hl kwd">\ln</span>(B) + \infty = \infty
$$


```{r p5.func_prob5B}

func_margInfty &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(k, B){
  scales::<span class="hl kwd">rescale</span>(<span class="hl kwd">marginal</span>(k, B), to=<span class="hl kwd">c</span>(0, 1/B))
}

func_problem5C &lt;- <span class="hl kwd"><span class="hl kwa">function</span></span>(startseed, B, it){
  <span class="hl kwd">set.seed</span>(startseed)
  df &lt;- <span class="hl kwd">func_gibbs.p5</span>(B, it)

true.cdf &lt;-<span class="hl kwd">stat_function</span>(fun = func_margInfty, args = B, lwd = 1, linetype=<span class="hl str">&quot;solid&quot;</span>, col=<span class="hl str">&quot;maroon&quot;</span>)

plot.x &lt;- <span class="hl kwd">ggplot</span>(df, <span class="hl kwd">aes</span>(x)) + 
  <span class="hl kwd">xlim</span>(0, B)+
  <span class="hl kwd">ylim</span>(0, 1/B)+
  <span class="hl kwd">geom_histogram</span>(<span class="hl kwd">aes</span>(y=..density..), alpha=0.4) + 
  true.cdf +
  <span class="hl kwd">xlab</span>(<span class="hl str">&quot;X Chain Values&quot;</span>)+
  <span class="hl kwd">ggtitle</span>(<span class="hl str">&quot;Marginal of X: Histogram and True Curve&quot;</span>)

plot.y &lt;- <span class="hl kwd">ggplot</span>(df, <span class="hl kwd">aes</span>(y)) +
  <span class="hl kwd">xlim</span>(0, B)+
  <span class="hl kwd">ylim</span>(0, 1/B)+
  <span class="hl kwd">geom_histogram</span>(<span class="hl kwd">aes</span>(y=..density..), alpha=0.4) + 
  true.cdf +
  <span class="hl kwd">xlab</span>(<span class="hl str">&quot;Y Chain Values&quot;</span>)+
  <span class="hl kwd">ggtitle</span>(<span class="hl str">&quot;Marginal of Y: Histogram and True Curve&quot;</span>)

<span class="hl kwd">grid.arrange</span>(plot.x, plot.y, nrow=1)

}
```


```{r p5RESULTS, message=<span class="hl kwa">FALSE</span>, warning=<span class="hl kwa">FALSE</span>}
<span class="hl kwd">func_problem5C</span>(530, 1e08, 100000)
```

```{r PRINTCODE}
<span class="hl com">#PRINTING THE CODE</span>
#knitr::<span class="hl kwd">stitch</span>(<span class="hl str">&quot;HW06.Rmd&quot;</span>) to go to latex
#knitr::<span class="hl kwd">stitch</span>(   script=<span class="hl str">&quot;STAT457-FINAL.Rmd&quot;</span>  , <span class="hl kwd">system.file</span>(<span class="hl str">&quot;misc&quot;</span>, <span class="hl str">&quot;knitr-template.Rhtml&quot;</span>, package=<span class="hl str">&quot;knitr&quot;</span>)) #code to HTML
```
</pre></div>
<div class="error"><pre class="knitr r">## Error: &lt;text&gt;:10:3: unexpected input
## 9: header-includes: 
## 10: - \
##       ^
</pre></div>
</div></div>

  <p>The R session information (including the OS info, R version and all
    packages used):</p>

<div class="chunk" id="session-info"><div class="rcode"><div class="source"><pre class="knitr r">    <span class="hl kwd">sessionInfo</span><span class="hl std">()</span>
</pre></div>
<div class="output"><pre class="knitr r">## R version 3.6.1 (2019-07-05)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17763)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] grid      stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] invgamma_1.1        MCMCpack_1.4-4      MASS_7.3-51.4       coda_0.19-3        
##  [5] gtable_0.3.0        numDeriv_2016.8-1.1 matlib_0.9.2        readr_1.3.1        
##  [9] dplyr_0.8.3         latex2exp_0.4.0     gridExtra_2.3       ggplot2_3.2.1      
## [13] knitr_1.24         
## 
## loaded via a namespace (and not attached):
##  [1] httr_1.4.1              jsonlite_1.6            viridisLite_0.3.0      
##  [4] carData_3.0-2           shiny_1.3.2             assertthat_0.2.1       
##  [7] highr_0.8               cellranger_1.1.0        yaml_2.2.0             
## [10] pillar_1.4.2            backports_1.1.4         lattice_0.20-38        
## [13] quantreg_5.51           glue_1.3.1              digest_0.6.20          
## [16] manipulateWidget_0.10.0 promises_1.0.1          rvest_0.3.4            
## [19] colorspace_1.4-1        htmltools_0.3.6         httpuv_1.5.1           
## [22] Matrix_1.2-17           pkgconfig_2.0.2         SparseM_1.77           
## [25] haven_2.1.1             purrr_0.3.2             xtable_1.8-4           
## [28] scales_1.0.0            webshot_0.5.1           openxlsx_4.1.0.1       
## [31] later_0.8.0             rio_0.5.16              MatrixModels_0.4-1     
## [34] tibble_2.1.3            car_3.0-3               withr_2.1.2            
## [37] lazyeval_0.2.2          magrittr_1.5            crayon_1.3.4           
## [40] readxl_1.3.1            mime_0.7                mcmc_0.9-6             
## [43] evaluate_0.14           forcats_0.4.0           xml2_1.2.2             
## [46] foreign_0.8-71          tools_3.6.1             data.table_1.12.4      
## [49] hms_0.5.0               stringr_1.4.0           munsell_0.5.0          
## [52] zip_2.0.4               kableExtra_1.1.0        compiler_3.6.1         
## [55] rlang_0.4.0             rstudioapi_0.10         htmlwidgets_1.5.1      
## [58] crosstalk_1.0.0         miniUI_0.1.1.1          labeling_0.3           
## [61] rmarkdown_1.14          abind_1.4-5             curl_4.2               
## [64] R6_2.4.0                zeallot_0.1.0           stringi_1.4.3          
## [67] Rcpp_1.0.2              vctrs_0.2.0             rgl_0.100.30           
## [70] tidyselect_0.2.5        xfun_0.8
</pre></div>
<div class="source"><pre class="knitr r">    <span class="hl kwd">Sys.time</span><span class="hl std">()</span>
</pre></div>
<div class="output"><pre class="knitr r">## [1] &quot;2019-12-11 12:08:17 CST&quot;
</pre></div>
</div></div>


</body>
</html>
